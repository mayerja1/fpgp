{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "import plotting_tools\n",
    "import utils\n",
    "import symb_reg as sr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deap import tools\n",
    "\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths1 = ('data/f2_1e7_evals_exact', \n",
    "               'data/f2_1e7_evals_coev_32predsz', 'data/f2_1e7_evals_coev_64predsz')\n",
    "data_paths2 = ('data/f2_3.5e7_evals_coev_32predsz','data/f2_3.5e7_evals_exact',\n",
    "               'data/f2_3.5e7_evals_dynamic', 'data/f2_3.5e7_evals_static')\n",
    "data_paths3 = ('data/f1_3.5e7_evals_exact', 'data/f1_3.5e7_evals_coev_32predsz')\n",
    "exp1 = list(map(utils.LoadedLogs, data_paths1)), ['exact', 'coev, size 32', 'coev, size 64']\n",
    "exp2 = list(map(utils.LoadedLogs, data_paths2)), ['coev', 'exact', 'dynamic', 'static']\n",
    "exp3 = list(map(utils.LoadedLogs, data_paths3)), ['exact', 'coev_32']\n",
    "exp4 = [utils.LoadedLogs('data/f2_1e7_evals_coev_8predsz')], ['coev, size 8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(data_paths1[0] + '/dataset.npz')\n",
    "trn_x, trn_y = data['trn_x'], data['trn_y']\n",
    "exp, names = exp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_tools.compare_performance(exp, 'evals', 'test_set_f', method_names=names, ignore_tresh=30, xlabel='Evaluations', ylabel='Test set fitness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select runs\n",
    "runs = list(list(exp)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of test set fitnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([l[-1]['test_set_f'] for l in runs])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_logs = sorted(runs, key=lambda x: x[-1]['test_set_f'])\n",
    "# select run you want to analyze\n",
    "log = sorted_logs[1] # best run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in sorted_logs:\n",
    "    plotting_tools.show_performance(l, 'evals', 'test_set_f')\n",
    "    print(l.select('test_set_f')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Found solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(trn_x, log[-1]['best_sol_vals'], label='best solution found')\n",
    "ax.plot(trn_x, trn_y, ls=' ', marker='o', ms='1', label='target function')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of used predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_tools.predictor_histogram(trn_x, trn_y, log)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animation of the progress of the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = plotting_tools.visualize_run(trn_x, trn_y, log, freq=50, step=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
